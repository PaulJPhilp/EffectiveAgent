import { ModelCapability } from '@/schema.js'
import type { FinishReason, Metadata, ReasoningDetail, ResponseMessage, Source, Usage, Warning } from '@/types.js'
import { AnthropicProvider, AnthropicProviderSettings } from '@ai-sdk/anthropic'
import { DeepSeekProvider, DeepSeekProviderSettings } from '@ai-sdk/deepseek'
import { GoogleGenerativeAIProvider, GoogleGenerativeAIProviderSettings } from '@ai-sdk/google'
import { GroqProvider, GroqProviderSettings } from '@ai-sdk/groq'
import { OpenAIProvider, OpenAIProviderSettings } from '@ai-sdk/openai'
import { PerplexityProvider, PerplexityProviderSettings } from '@ai-sdk/perplexity'
import { LanguageModelV1 } from '@ai-sdk/provider'
import { XaiProvider, XaiProviderSettings } from '@ai-sdk/xai'
import { CoreMessage } from 'ai'
import { Effect } from 'effect'

/**
 * Base result type containing common fields for all AI generation results
 */
export interface GenerateBaseResult {
    /** Unique identifier of the response */
    id: string
    /** Model identifier used for generation */
    model: string
    /** Timestamp of the response */
    timestamp: Date
    /** Reason the generation finished */
    finishReason: FinishReason
    /** Token/compute usage details */
    usage: Usage
    /** Provider-specific metadata */
    providerMetadata?: Metadata
    /** Optional raw response headers */
    headers?: Record<string, string>
    /** Optional raw response body */
    body?: unknown
}

/**
 * Output type for generateText based on Vercel AI SDK GenerateTextResult
 */
export interface GenerateTextResult extends GenerateBaseResult {
    /** Full text generated by the model */
    text: string
    /** Optional reasoning text */
    reasoning?: string
    /** Detailed reasoning parts */
    reasoningDetails?: ReasoningDetail[]
    /** Sources used during generation */
    sources?: Source[]
    /** Response messages generated (for chat or tool calls) */
    messages?: ResponseMessage[]
    /** Warnings from the provider */
    warnings?: Warning[]
}

/**
 * Output type for chat endpoint, same structure as GenerateTextResult
 */
export type ChatResult = GenerateTextResult

/**
 * Output type for generateObject based on Vercel AI SDK GenerateObjectResult
 */
export interface GenerateObjectResult<T> extends GenerateBaseResult {
    /** Generated object conforming to the provided schema */
    object: T
}

/**
 * Output type for generateImage based on Vercel AI SDK ImageGenerationResult
 */
export interface GenerateImageResult extends GenerateBaseResult {
    /** Generated image URL or base64 data */
    imageUrl: string
    /** Optional additional generated images (for multiple variations) */
    additionalImages?: string[]
    /** Image generation parameters used */
    parameters: {
        /** Size of the generated image (e.g., '1024x1024') */
        size?: string
        /** Quality setting used for generation */
        quality?: string
        /** Style setting used for generation */
        style?: string
    }
}

/**
 * Output type for generateSpeech based on Vercel AI SDK SpeechGenerationResult
 */
export interface GenerateSpeechResult extends GenerateBaseResult {
    /** Generated audio data as base64 string or URL */
    audioData: string
    /** Audio format of the generated speech (e.g., 'mp3', 'wav') */
    format: string
    /** Speech generation parameters used */
    parameters: {
        /** Voice ID or name used for generation */
        voice?: string
        /** Speed/rate of speech (e.g., '1.0') */
        speed?: string
        /** Pitch adjustment (e.g., '0') */
        pitch?: string
        /** Language code (e.g., 'en-US') */
        language?: string
    }
    /** Duration of the generated audio in seconds */
    duration?: number
}

/**
 * Output type for transcribe based on Vercel AI SDK TranscriptionResult
 */
export interface TranscribeResult extends GenerateBaseResult {
    /** Full transcribed text */
    text: string
    /** Detailed transcription segments with timing */
    segments?: Array<{
        /** Segment ID */
        id: number
        /** Start time in seconds */
        start: number
        /** End time in seconds */
        end: number
        /** Transcribed text for this segment */
        text: string
        /** Confidence score (0-1) */
        confidence?: number
        /** Speaker label if speaker diarization is enabled */
        speaker?: string
        /** Language detected for this segment */
        language?: string
    }>
    /** Language detected in the audio */
    detectedLanguage?: string
    /** Duration of the audio in seconds */
    duration: number
    /** Audio processing parameters used */
    parameters: {
        /** Language hint provided (e.g., 'en-US') */
        language?: string
        /** Whether speaker diarization was enabled */
        diarization?: boolean
        /** Whether timestamps were enabled */
        timestamps?: boolean
        /** Audio quality settings used */
        quality?: string
    }
}

/**
 * Output type for streamText based on Vercel AI SDK StreamingTextResult
 */
export interface StreamingTextResult extends GenerateBaseResult {
    /** Current chunk of generated text */
    chunk: string
    /** Full text generated so far */
    text: string
    /** Whether this is the final chunk */
    isLast: boolean
    /** Current token count */
    currentTokenCount: number
    /** Optional reasoning text */
    reasoning?: string
    /** Detailed reasoning parts */
    reasoningDetails?: ReasoningDetail[]
    /** Sources used during generation */
    sources?: Source[]
    /** Response messages generated (for chat or tool calls) */
    messages?: ResponseMessage[]
    /** Warnings from the provider */
    warnings?: Warning[]
    /** Stream control functions */
    controller: {
        /** Function to pause the stream */
        pause: () => void
        /** Function to resume the stream */
        resume: () => void
        /** Function to cancel the stream */
        cancel: () => void
        /** Whether the stream is currently paused */
        isPaused: boolean
    }
}

/**
 * Output type for streamObject based on Vercel AI SDK StreamingObjectResult
 */
export interface StreamingObjectResult<T> extends GenerateBaseResult {
    /** Current chunk of generated object */
    chunk: Partial<T>
    /** Full object generated so far */
    object: Partial<T>
    /** Whether this is the final chunk */
    isLast: boolean
    /** Current token count */
    currentTokenCount: number
    /** Stream control functions */
    controller: {
        /** Function to pause the stream */
        pause: () => void
        /** Function to resume the stream */
        resume: () => void
        /** Function to cancel the stream */
        cancel: () => void
        /** Whether the stream is currently paused */
        isPaused: boolean
    }
}

/**
 * Output type for generateEmbeddings based on Vercel AI SDK EmbeddingGenerationResult
 */
export interface GenerateEmbeddingsResult extends GenerateBaseResult {
    /** Array of embedding vectors */
    embeddings: number[][]
    /** Dimensions of each embedding vector */
    dimensions: number
    /** Original texts that were embedded */
    texts: string[]
    /** Optional similarity scores if comparing to other embeddings */
    similarityScores?: number[]
    /** Parameters used for embedding generation */
    parameters: {
        /** Model-specific parameters like truncation, pooling strategy */
        modelParameters?: Record<string, unknown>
        /** Normalization method applied (if any) */
        normalization?: string
        /** Text preprocessing steps applied */
        preprocessing?: string[]
    }
}

/**
 * Discriminated union type for all supported AI providers.
 * Each provider has a unique 'name' property that acts as the discriminator.
 */
export type EffectiveProviderApi =
    | { name: "openai"; provider: OpenAIProvider; capabilities: Set<ModelCapability> }
    | { name: "anthropic"; provider: AnthropicProvider; capabilities: Set<ModelCapability> }
    | { name: "google"; provider: GoogleGenerativeAIProvider; capabilities: Set<ModelCapability> }
    | { name: "xai"; provider: XaiProvider; capabilities: Set<ModelCapability> }
    | { name: "perplexity"; provider: PerplexityProvider; capabilities: Set<ModelCapability> }
    | { name: "groq"; provider: GroqProvider; capabilities: Set<ModelCapability> }
    | { name: "deepseek"; provider: DeepSeekProvider; capabilities: Set<ModelCapability> }

/**
 * Union type for all supported provider settings.
 */
export type EffectiveProviderSettings =
    | { name: "openai"; settings: OpenAIProviderSettings }
    | { name: "anthropic"; settings: AnthropicProviderSettings }
    | { name: "google"; settings: GoogleGenerativeAIProviderSettings }
    | { name: "xai"; settings: XaiProviderSettings }
    | { name: "perplexity"; settings: PerplexityProviderSettings }
    | { name: "groq"; settings: GroqProviderSettings }
    | { name: "deepseek"; settings: DeepSeekProviderSettings }

/**
* Options for generating text using a language model
*/
export interface GenerateTextOptions {
    /**
     * The language model to use for text generation
     */
    readonly model: LanguageModelV1;
    /**
     * The prompt to generate text from
     */
    readonly prompt: string;
    /**
     * Optional array of messages for chat-based models
     */
    readonly messages?: CoreMessage[];

    /**
     * The maximum number of steps to take in the generation process
     */
    maxSteps?: number;

    /**
     * The signal to abort the generation process
     */
    abortSignal?: AbortSignal;

    /**
     * The maximum number of retries to attempt in the generation process
     */
    maxRetries?: number;

    /** 
     * The temperature to use in the generation process
     */
    temperature?: number;

    /**
     * The top-p value to use in the generation process
     */
    topP?: number;

    /**
     * The top-k value to use in the generation process
     */
    topK?: number;

    /**
     * The presence penalty to use in the generation process
     */
    presencePenalty?: number;

    /**
     * 
     */
    frequencyPenalty?: number;

    /**
     * The seed to use in the generation process
     */
    seed?: number;

    /**
     * The stop sequences to use in the generation process
     */
    stop?: string[];

    /**
     * 
     */
}

/**
 * Options for streaming text using a language model
 */
export interface StreamTextOptions extends GenerateTextOptions {
    onToken?: (token: string) => void;
}

/**
 * Options for chat generation
 */
export interface ChatOptions {
    modelId: string;
    messages: CoreMessage[];
    system?: string;
    onToken?: (token: string) => void;
}

/**
 * Core provider client API interface that all providers must implement.
 * Methods are specifically typed to match capabilities and return types.
 */
export interface ProviderClientApi {
    /**
     * Generate text completion from a prompt
     */
    generateText(options: GenerateTextOptions): Effect.Effect<GenerateTextResult, Error>

    /**
     * Stream text completion from a prompt
     */
    streamText(options: StreamTextOptions): Effect.Effect<StreamingTextResult, Error>

    /**
     * Generate a structured object based on a schema
     */
    generateObject<T>(options: GenerateTextOptions & { schema: unknown }): Effect.Effect<GenerateObjectResult<T>, Error>

    /**
     * Stream a structured object based on a schema
     */
    streamObject<T>(options: StreamTextOptions & { schema: unknown }): Effect.Effect<StreamingObjectResult<T>, Error>

    /**
     * Generate chat completion from messages
     */
    chat(options: ChatOptions): Effect.Effect<ChatResult, Error>

    /**
     * Generate embeddings for one or more texts
     */
    generateEmbeddings(texts: string[], options?: {
        model?: string
        batchSize?: number
    }): Effect.Effect<GenerateEmbeddingsResult, Error>

    /**
     * Generate images from a text prompt
     */
    generateImage(prompt: string, options?: {
        model?: string
        size?: string
        quality?: string
        style?: string
        n?: number
    }): Effect.Effect<GenerateImageResult, Error>

    /**
     * Generate speech from text
     */
    generateSpeech(text: string, options?: {
        model?: string
        voice?: string
        speed?: string
        pitch?: string
        language?: string
    }): Effect.Effect<GenerateSpeechResult, Error>

    /**
     * Transcribe speech to text
     */
    transcribe(audioData: string | Uint8Array, options?: {
        model?: string
        language?: string
        diarization?: boolean
        timestamps?: boolean
        quality?: string
    }): Effect.Effect<TranscribeResult, Error>

    /**
     * Get the capabilities supported by this provider
     */
    getCapabilities(): Set<ModelCapability>

    /**
     * Get the available models for this provider
     */
    getModels(): Effect.Effect<LanguageModelV1[], Error>

    /**
     * Get the name of the provider
     */
    getProviderName(): string

    /**
     * Set up the provider for use with Vercel AI SDK
     */
    setVercelProvider(): Effect.Effect<void, Error>
}