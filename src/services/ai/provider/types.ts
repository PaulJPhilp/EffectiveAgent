import { ModelCapability } from '@/schema.js'
import { EffectiveInput } from "@/services/ai/input/service.js"
import type { FinishReason, Metadata, ReasoningDetail, ResponseMessage, Source, Usage, Warning } from '@/types.js'
import { AnthropicProvider, AnthropicProviderSettings } from '@ai-sdk/anthropic'
import { DeepSeekProvider, DeepSeekProviderSettings } from '@ai-sdk/deepseek'
import { GoogleGenerativeAIProvider, GoogleGenerativeAIProviderSettings } from '@ai-sdk/google'
import { GroqProvider, GroqProviderSettings } from '@ai-sdk/groq'
import { OpenAIProvider, OpenAIProviderSettings } from '@ai-sdk/openai'
import { PerplexityProvider, PerplexityProviderSettings } from '@ai-sdk/perplexity'
import { LanguageModelV1, LanguageModelV1Prompt } from '@ai-sdk/provider'
import { XaiProvider, XaiProviderSettings } from '@ai-sdk/xai'
import { Effect } from 'effect'
import * as Stream from "effect/Stream"
import { ProviderConfigError } from '../errors.js'
import { ProvidersType } from './schema.js'

// Re-export types from @ai-sdk/provider
export type { LanguageModelV1, LanguageModelV1Prompt } from '@ai-sdk/provider'

// Re-export providers
export {
    AnthropicProvider,
    DeepSeekProvider,
    GoogleGenerativeAIProvider,
    GroqProvider,
    OpenAIProvider,
    PerplexityProvider,
    XaiProvider
}

// Re-export provider settings
export type {
    AnthropicProviderSettings,
    DeepSeekProviderSettings,
    GoogleGenerativeAIProviderSettings,
    GroqProviderSettings,
    OpenAIProviderSettings,
    PerplexityProviderSettings,
    XaiProviderSettings
}

// Re-export types from @/types.js
export type {
    FinishReason,
    Metadata as ProviderMetadata,
    Usage,
    Warning
}

/**
 * Base result type containing common fields for all AI generation results
 */
export interface GenerateBaseResult {
    /** Unique identifier of the response */
    id: string
    /** Model identifier used for generation */
    model: string
    /** Timestamp of the response */
    timestamp: Date
    /** Reason the generation finished */
    finishReason: FinishReason
    /** Token/compute usage details */
    usage: Usage
    /** Provider-specific metadata */
    providerMetadata?: Metadata
    /** Optional raw response headers */
    headers?: Record<string, string>
    /** Optional raw response body */
    body?: unknown
}

/**
 * Output type for generateText based on Vercel AI SDK GenerateTextResult
 */
export interface GenerateTextResult extends GenerateBaseResult {
    /** Full text generated by the model */
    text: string
    /** Optional reasoning text */
    reasoning?: string
    /** Detailed reasoning parts */
    reasoningDetails?: ReasoningDetail[]
    /** Sources used during generation */
    sources?: Source[]
    /** Response messages generated (for chat or tool calls) */
    messages?: ResponseMessage[]
    /** Warnings from the provider */
    warnings?: Warning[]
}

/**
 * Output type for chat endpoint, same structure as GenerateTextResult
 */
export type ChatResult = GenerateTextResult

/**
 * Output type for generateObject based on Vercel AI SDK GenerateObjectResult
 */
export interface GenerateObjectResult<T> extends GenerateBaseResult {
    /** Generated object conforming to the provided schema */
    object: T
}

/**
 * Output type for generateImage based on Vercel AI SDK ImageGenerationResult
 */
export interface GenerateImageResult extends GenerateBaseResult {
    /** Generated image URL or base64 data */
    imageUrl: string
    /** Optional additional generated images (for multiple variations) */
    additionalImages?: string[]
    /** Image generation parameters used */
    parameters: {
        /** Size of the generated image (e.g., '1024x1024') */
        size?: string
        /** Quality setting used for generation */
        quality?: string
        /** Style setting used for generation */
        style?: string
    }
}

/**
 * Output type for generateSpeech based on Vercel AI SDK SpeechGenerationResult
 */
export interface GenerateSpeechResult extends GenerateBaseResult {
    /** Generated audio data as base64 string or URL */
    audioData: string
    /** Audio format of the generated speech (e.g., 'mp3', 'wav') */
    format: string
    /** Speech generation parameters used */
    parameters: {
        /** Voice ID or name used for generation */
        voice?: string
        /** Speed/rate of speech (e.g., '1.0') */
        speed?: string
        /** Pitch adjustment (e.g., '0') */
        pitch?: string
        /** Language code (e.g., 'en-US') */
        language?: string
    }
    /** Duration of the generated audio in seconds */
    duration?: number
}

/**
 * Output type for transcribe based on Vercel AI SDK TranscriptionResult
 */
export interface TranscribeResult extends GenerateBaseResult {
    /** Full transcribed text */
    text: string
    /** Detailed transcription segments with timing */
    segments?: Array<{
        /** Segment ID */
        id: number
        /** Start time in seconds */
        start: number
        /** End time in seconds */
        end: number
        /** Transcribed text for this segment */
        text: string
        /** Confidence score (0-1) */
        confidence?: number
        /** Speaker label if speaker diarization is enabled */
        speaker?: string
        /** Language detected for this segment */
        language?: string
    }>
    /** Language detected in the audio */
    detectedLanguage?: string
    /** Duration of the audio in seconds */
    duration: number
    /** Audio processing parameters used */
    parameters: {
        /** Language hint provided (e.g., 'en-US') */
        language?: string
        /** Whether speaker diarization was enabled */
        diarization?: boolean
        /** Whether timestamps were enabled */
        timestamps?: boolean
        /** Audio quality settings used */
        quality?: string
    }
}

/**
 * Output type for streamText based on Vercel AI SDK StreamingTextResult
 */
export interface StreamingTextResult extends GenerateBaseResult {
    /** Current chunk of generated text */
    chunk: string
    /** Full text generated so far */
    text: string
    /** Whether this is the final chunk */
    isLast: boolean
    /** Current token count */
    currentTokenCount: number
    /** Optional reasoning text */
    reasoning?: string
    /** Detailed reasoning parts */
    reasoningDetails?: ReasoningDetail[]
    /** Sources used during generation */
    sources?: Source[]
    /** Response messages generated (for chat or tool calls) */
    messages?: ResponseMessage[]
    /** Warnings from the provider */
    warnings?: Warning[]
    /** Stream control functions */
    controller: {
        /** Function to pause the stream */
        pause: () => void
        /** Function to resume the stream */
        resume: () => void
        /** Function to cancel the stream */
        cancel: () => void
        /** Whether the stream is currently paused */
        isPaused: boolean
    }
}

/**
 * Output type for streamObject based on Vercel AI SDK StreamingObjectResult
 */
export interface StreamingObjectResult<T> extends GenerateBaseResult {
    /** Current chunk of generated object */
    chunk: Partial<T>
    /** Full object generated so far */
    object: Partial<T>
    /** Whether this is the final chunk */
    isLast: boolean
    /** Current token count */
    currentTokenCount: number
    /** Stream control functions */
    controller: {
        /** Function to pause the stream */
        pause: () => void
        /** Function to resume the stream */
        resume: () => void
        /** Function to cancel the stream */
        cancel: () => void
        /** Whether the stream is currently paused */
        isPaused: boolean
    }
}

/**
 * Output type for generateEmbeddings based on Vercel AI SDK EmbeddingGenerationResult
 */
export interface GenerateEmbeddingsResult extends GenerateBaseResult {
    /** Array of embedding vectors */
    embeddings: number[][]
    /** Dimensions of each embedding vector */
    dimensions: number
    /** Original texts that were embedded */
    texts: string[]
    /** Optional similarity scores if comparing to other embeddings */
    similarityScores?: number[]
    /** Parameters used for embedding generation */
    parameters: {
        /** Model-specific parameters like truncation, pooling strategy */
        modelParameters?: Record<string, unknown>
        /** Normalization method applied (if any) */
        normalization?: string
        /** Text preprocessing steps applied */
        preprocessing?: string[]
    }
}

/**
 * Standardized response wrapper for AI provider operations.
 */
export interface EffectiveResponse<TData> {
    /** The core data payload (e.g., GenerateTextResult, GenerateObjectResult) */
    readonly data: TData;
    /** Common metadata (can be extended if needed) */
    readonly metadata: {
        readonly model?: string;
        readonly id: string;
        readonly timestamp: Date;
        readonly usage?: Usage;
        readonly finishReason?: FinishReason;
        readonly providerMetadata?: Metadata;
    };
}

/**
 * Base options common to many provider API calls.
 */
export interface BaseProviderOptions {
    /** The specific model ID to use for the operation */
    readonly modelId: string;
    /** Optional tracing span */
    // readonly span?: Span; // TODO: Decide if span is passed explicitly or via Effect context
    /** Optional common generation parameters */
    readonly parameters?: {
        /** Maximum retries on failure */
        maxRetries?: number;
        /** Temperature (0-2) */
        temperature?: number;
        /** Top-p sampling */
        topP?: number;
        /** Top-k sampling */
        topK?: number;
        /** Presence penalty */
        presencePenalty?: number;
        /** Frequency penalty */
        frequencyPenalty?: number;
        /** Random seed */
        seed?: number;
        /** Stop sequences */
        stop?: string[];
        /** Maximum generation steps/tokens (provider specific interpretation) */
        maxTokens?: number; // Renamed from maxSteps for clarity
    };
    /** Optional signal to abort the operation */
    readonly abortSignal?: AbortSignal;
}

/**
 * Options specific to text generation.
 */
export interface ProviderGenerateTextOptions extends BaseProviderOptions {
    /** Optional system prompt or instructions */
    readonly system?: string;
}

/**
 * Options specific to object generation.
 */
export interface ProviderGenerateObjectOptions<T> extends BaseProviderOptions {
    /** The schema for the object to be generated */
    readonly schema: unknown; // Keeping as unknown for now, consistent with Vercel AI SDK
    /** Optional system prompt or instructions */
    readonly system?: string;
}

/**
 * Options specific to chat generation.
 */
export interface ProviderChatOptions extends BaseProviderOptions {
    /** Optional system prompt or instructions */
    readonly system?: string;
}

/**
 * Options specific to embedding generation.
 */
export interface ProviderGenerateEmbeddingsOptions extends BaseProviderOptions {
    /** Optional batch size for processing embeddings */
    readonly batchSize?: number;
}

/**
 * Options specific to image generation.
 */
export interface ProviderGenerateImageOptions extends BaseProviderOptions {
    /** Number of images to generate */
    readonly n?: number;
    /** Desired size of the image (e.g., '1024x1024') */
    readonly size?: string;
    /** Quality setting (e.g., 'hd', 'standard') */
    readonly quality?: string;
    /** Artistic style (e.g., 'vivid', 'natural') */
    readonly style?: string;
}

/**
 * Options specific to speech generation.
 */
export interface ProviderGenerateSpeechOptions extends BaseProviderOptions {
    /** Voice ID or name */
    readonly voice?: string;
    /** Speed/rate adjustment */
    readonly speed?: string;
}

/**
 * Options specific to transcription.
 */
export interface ProviderTranscribeOptions extends BaseProviderOptions {
    /** Language hint */
    readonly language?: string;
    /** Enable speaker diarization */
    readonly diarization?: boolean;
    /** Enable timestamps */
    readonly timestamps?: boolean;
}

/**
 * Discriminated union type for all supported AI providers.
 * Each provider has a unique 'name' property that acts as the discriminator.
 */
/**
 * Discriminated union type for Vercel AI SDK providers
 */
export type VercelProvider =
    | { type: "openai"; provider: OpenAIProvider }
    | { type: "anthropic"; provider: AnthropicProvider }
    | { type: "google"; provider: GoogleGenerativeAIProvider }
    | { type: "xai"; provider: XaiProvider }
    | { type: "perplexity"; provider: PerplexityProvider }
    | { type: "groq"; provider: GroqProvider }
    | { type: "deepseek"; provider: DeepSeekProvider }

export type EffectiveProviderApi =
    | { name: "openai"; provider: OpenAIProvider; capabilities: Set<ModelCapability> }
    | { name: "anthropic"; provider: AnthropicProvider; capabilities: Set<ModelCapability> }
    | { name: "google"; provider: GoogleGenerativeAIProvider; capabilities: Set<ModelCapability> }
    | { name: "xai"; provider: XaiProvider; capabilities: Set<ModelCapability> }
    | { name: "perplexity"; provider: PerplexityProvider; capabilities: Set<ModelCapability> }
    | { name: "groq"; provider: GroqProvider; capabilities: Set<ModelCapability> }
    | { name: "deepseek"; provider: DeepSeekProvider; capabilities: Set<ModelCapability> }
    | { name: "openrouter"; provider: unknown; capabilities: Set<ModelCapability> } // TODO: Replace 'unknown' with actual OpenRouterProvider type when available

/**
 * Union type for all supported provider settings.
 */
export type EffectiveProviderSettings =
    | { name: "openai"; settings: OpenAIProviderSettings }
    | { name: "anthropic"; settings: AnthropicProviderSettings }
    | { name: "google"; settings: GoogleGenerativeAIProviderSettings }
    | { name: "xai"; settings: XaiProviderSettings }
    | { name: "perplexity"; settings: PerplexityProviderSettings }
    | { name: "groq"; settings: GroqProviderSettings }
    | { name: "deepseek"; settings: DeepSeekProviderSettings }
    | { name: "openrouter"; settings: unknown } // TODO: Replace 'unknown' with actual OpenRouterProviderSettings when available

/**
 * Core provider client API interface that all providers must implement.
 * Methods are specifically typed to match capabilities and return types.
 */
export interface ProviderClientApi {
    /**
     * Generate text completion from input.
     */
    generateText(input: EffectiveInput, options: ProviderGenerateTextOptions): Effect.Effect<EffectiveResponse<GenerateTextResult>, Error>;

    /**
     * Stream text completion from input.
     */
    streamText(input: EffectiveInput, options: ProviderGenerateTextOptions): Stream.Stream<EffectiveResponse<StreamingTextResult>, Error>;

    /**
     * Generate a structured object based on a schema from input.
     */
    generateObject<T>(input: EffectiveInput, options: ProviderGenerateObjectOptions<T>): Effect.Effect<EffectiveResponse<GenerateObjectResult<T>>, Error>;

    /**
     * Stream a structured object based on a schema from input.
     */
    streamObject<T>(input: EffectiveInput, options: ProviderGenerateObjectOptions<T>): Stream.Stream<EffectiveResponse<StreamingObjectResult<T>>, Error>;

    /**
     * Generate chat completion from input messages.
     */
    chat(input: EffectiveInput, options: ProviderChatOptions): Effect.Effect<EffectiveResponse<ChatResult>, Error>;

    /**
     * Stream chat completion from input messages.
     */
    streamChat(input: EffectiveInput, options: ProviderChatOptions): Stream.Stream<EffectiveResponse<StreamingTextResult>, Error>;

    /**
     * Generate embeddings for texts provided in the input.
     * Note: Input needs adaptation to extract texts.
     */
    generateEmbeddings(input: EffectiveInput, options: ProviderGenerateEmbeddingsOptions): Effect.Effect<EffectiveResponse<GenerateEmbeddingsResult>, Error>;

    /**
     * Generate images from a text prompt provided in the input.
     * Note: Input needs adaptation to extract prompt.
     */
    generateImage(input: EffectiveInput, options: ProviderGenerateImageOptions): Effect.Effect<EffectiveResponse<GenerateImageResult>, Error>;

    /**
     * Generate speech from text provided in the input.
     * Note: Input needs adaptation to extract text.
     */
    generateSpeech(input: EffectiveInput, options: ProviderGenerateSpeechOptions): Effect.Effect<EffectiveResponse<GenerateSpeechResult>, Error>;

    /**
     * Transcribe speech to text from audio data provided in the input.
     * Note: Input needs adaptation to extract audio data.
     */
    transcribe(input: EffectiveInput, options: ProviderTranscribeOptions): Effect.Effect<EffectiveResponse<TranscribeResult>, Error>;

    /**
     * Get the capabilities supported by this provider client instance.
     */
    getCapabilities(): Effect.Effect<Set<ModelCapability>, ProviderConfigError>;

    /**
     * Get the available models usable by this provider client.
     */
    getModels(): Effect.Effect<LanguageModelV1[], Error>;

    /**
     * Get the name of the provider associated with this client instance.
     */
    getProviderName(): Effect.Effect<string, ProviderConfigError>;

    /**
     * Initialize the provider client (e.g., set API key and endpoint).
     * Returns the initialized provider details.
     */
    setVercelProvider(providerName: ProvidersType, apiKey: string): Effect.Effect<void, ProviderConfigError>;
}