{
  "name": "Model Configurations",
  "version": "0.1.0",
  "description": "Configuration for all available models",
  "models": [
    {
      "id": "gpt-35-turbo",
      "name": "GPT-3.5 Turbo",
      "version": "0.1.0",
      "provider": "openai",
      "modelName": "gpt-3.5-turbo",
      "maxTokens": 8192,
      "contextWindowSize": "medium-context-window",
      "costPer1kTokens": 0.002,
      "capabilities": ["text-generation", "chat"],
      "metadata": {
        "description": "GPT-3.5 Turbo model optimized for chat"
      },
      "rateLimit": {
        "requestsPerMinute": 3500
      }
    },
    {
      "id": "gemini-2-flash",
      "name": "Gemini 2.0 Flash",
      "version": "0.1.0",
      "provider": "google",
      "modelName": "gemini-2.0-flash",
      "maxTokens": 128000,
      "contextWindowSize": "large-context-window",
      "costPer1kTokens": 0.0015,
      "capabilities": ["text-generation", "chat", "function-calling", "code-generation", "reasoning"],
      "metadata": {
        "description": "Flash version of Gemini 2.0"
      },
      "rateLimit": {
        "requestsPerMinute": 1500
      }
    },
    {
      "id": "gemini-2-ultra",
      "name": "Gemini 2.0 Ultra",
      "version": "0.1.0",
      "provider": "google",
      "modelName": "gemini-2.0-ultra",
      "maxTokens": 128000,
      "contextWindowSize": "large-context-window",
      "costPer1kTokens": 0.003,
      "capabilities": ["text-generation", "chat", "function-calling", "code-generation", "reasoning"],
      "metadata": {
        "description": "Ultra version of Gemini 2.0"
      },
      "rateLimit": {
        "requestsPerMinute": 1000
      }
    },
    {
      "id": "dall-e-2",
      "name": "DALL-E 2",
      "version": "0.1.0",
      "provider": "openai",
      "modelName": "dall-e-2",
      "maxTokens": 1000,
      "contextWindowSize": "small-context-window",
      "costPer1kTokens": 0.016,
      "capabilities": ["text-to-image"],
      "metadata": {
        "description": "Image generation model from OpenAI"
      },
      "rateLimit": {
        "requestsPerMinute": 50
      }
    },
    {
      "id": "midjourney",
      "name": "Midjourney",
      "version": "0.1.0",
      "provider": "local",
      "modelName": "midjourney-v6",
      "maxTokens": 1000,
      "contextWindowSize": "small-context-window",
      "costPer1kTokens": 0.02,
      "capabilities": ["text-to-image"],
      "metadata": {
        "description": "Advanced image generation model"
      },
      "rateLimit": {
        "requestsPerMinute": 10
      }
    },
    {
      "id": "stable-diffusion-3",
      "name": "Stable Diffusion 3",
      "version": "0.1.0",
      "provider": "local",
      "modelName": "stable-diffusion-3",
      "maxTokens": 1000,
      "contextWindowSize": "small-context-window",
      "costPer1kTokens": 0.002,
      "capabilities": ["text-to-image"],
      "metadata": {
        "description": "Open source image generation model"
      },
      "rateLimit": {
        "requestsPerMinute": 20
      }
    },
    {
      "id": "claude-35-flash",
      "name": "Claude 3.5 Flash",
      "version": "0.1.0",
      "provider": "anthropic",
      "modelName": "claude-3.5-flash",
      "maxTokens": 200000,
      "contextWindowSize": "large-context-window",
      "costPer1kTokens": 0.0008,
      "capabilities": ["text-generation", "chat", "function-calling", "reasoning"],
      "metadata": {
        "description": "Fast version of Claude 3.5"
      },
      "rateLimit": {
        "requestsPerMinute": 150
      }
    },
    {
      "id": "text-embedding-3-small",
      "name": "Text Embedding 3 Small",
      "version": "0.1.0",
      "provider": "openai",
      "modelName": "text-embedding-3-small",
      "maxTokens": 8191,
      "contextWindowSize": "medium-context-window",
      "costPer1kTokens": 0.00002,
      "capabilities": ["embeddings"],
      "metadata": {
        "description": "Small text embedding model"
      },
      "rateLimit": {
        "requestsPerMinute": 3500
      }
    },
    {
      "id": "text-embedding-3-large",
      "name": "Text Embedding 3 Large",
      "version": "0.1.0",
      "provider": "openai",
      "modelName": "text-embedding-3-large",
      "maxTokens": 8191,
      "contextWindowSize": "medium-context-window",
      "costPer1kTokens": 0.00013,
      "capabilities": ["embeddings"],
      "metadata": {
        "description": "Large text embedding model"
      },
      "rateLimit": {
        "requestsPerMinute": 3000
      }
    },
    {
      "id": "llama-3-70b",
      "name": "LLaMA 3 70B",
      "version": "0.1.0",
      "provider": "local",
      "modelName": "llama-3-70b",
      "maxTokens": 8192,
      "contextWindowSize": "medium-context-window",
      "costPer1kTokens": 0.0015,
      "capabilities": ["reasoning", "code-generation"],
      "metadata": {
        "description": "70B parameter LLaMA 3 model"
      },
      "rateLimit": {
        "requestsPerMinute": 100
      }
    },
    {
      "id": "llama-3-8b",
      "name": "LLaMA 3 8B",
      "version": "0.1.0",
      "provider": "local",
      "modelName": "llama-3-8b",
      "maxTokens": 8192,
      "contextWindowSize": "medium-context-window",
      "costPer1kTokens": 0.0005,
      "capabilities": ["text-generation", "chat"],
      "metadata": {
        "description": "8B parameter LLaMA 3 model"
      },
      "rateLimit": {
        "requestsPerMinute": 500
      }
    },
    {
      "id": "grok-1",
      "name": "Grok 1",
      "version": "0.1.0",
      "provider": "grok",
      "modelName": "grok-1",
      "maxTokens": 131072,
      "contextWindowSize": "large-context-window",
      "costPer1kTokens": 0.005,
      "capabilities": ["search", "reasoning"],
      "metadata": {
        "description": "First generation Grok model"
      },
      "rateLimit": {
        "requestsPerMinute": 100
      }
    }
  ]
} 